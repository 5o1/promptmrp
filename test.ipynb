{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[ 1.4015e+00,  2.2392e-01, -7.1368e-01,  ...,  5.4553e-01,\n",
      "              8.0008e-01,  2.2032e+00],\n",
      "            [ 6.2017e-01,  1.3222e+00, -1.4368e+00,  ..., -8.0680e-01,\n",
      "             -1.1942e+00, -5.3413e-01],\n",
      "            [ 2.6717e-01, -5.1639e-01,  6.3839e-02,  ...,  1.6853e-01,\n",
      "              4.3607e-01, -4.7162e-01],\n",
      "            ...,\n",
      "            [ 9.9862e-01,  1.9589e-01, -1.4683e-01,  ..., -8.3430e-01,\n",
      "              1.1458e+00,  4.7351e-01],\n",
      "            [ 1.1168e+00,  1.2972e+00,  8.6369e-01,  ..., -1.3262e+00,\n",
      "             -3.4712e-01,  4.0201e-01],\n",
      "            [ 8.3891e-01,  5.9497e-01, -6.9541e-01,  ..., -2.3239e+00,\n",
      "             -1.0345e+00,  1.0839e+00]],\n",
      "\n",
      "           [[-7.4218e-01,  2.1893e-01,  1.9834e+00,  ...,  3.1377e-01,\n",
      "              4.8416e-01,  1.2442e+00],\n",
      "            [-1.3487e-01,  2.5122e-01, -2.6674e-01,  ..., -3.3199e-01,\n",
      "              4.0937e-01, -7.4979e-01],\n",
      "            [-2.3918e+00,  3.2513e-02,  5.1589e-01,  ...,  2.9973e-02,\n",
      "             -8.1205e-02,  8.2413e-01],\n",
      "            ...,\n",
      "            [ 1.9648e+00, -1.1223e+00, -1.1858e+00,  ..., -3.4353e-01,\n",
      "              4.8007e-01,  5.9445e-01],\n",
      "            [ 1.0103e+00,  4.2466e-01, -1.2474e+00,  ...,  2.8234e-01,\n",
      "             -8.2707e-01, -3.6520e-01],\n",
      "            [-1.8436e+00,  1.3860e+00,  2.2141e+00,  ...,  8.8840e-01,\n",
      "              6.0165e-01,  2.0110e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 7.6360e-01, -9.5353e-01, -1.6341e+00,  ..., -6.1870e-01,\n",
      "             -2.9422e-01,  1.2819e+00],\n",
      "            [-3.4578e-01, -2.7166e-01, -3.0431e-01,  ..., -6.9445e-01,\n",
      "              4.0232e-01,  1.2325e-01],\n",
      "            [-3.5377e-01,  6.6221e-01,  2.1946e+00,  ...,  1.2676e+00,\n",
      "              3.3872e-01, -8.6614e-01],\n",
      "            ...,\n",
      "            [-1.4983e-03,  9.7301e-01, -2.6194e+00,  ..., -9.5506e-01,\n",
      "              1.0429e+00,  1.7185e-01],\n",
      "            [ 1.1139e+00, -1.3768e+00, -1.8646e-01,  ...,  3.4137e-01,\n",
      "             -6.3183e-01,  6.2615e-02],\n",
      "            [ 1.0682e+00,  8.1373e-01, -1.1948e+00,  ...,  3.6587e-01,\n",
      "             -6.0225e-01,  1.9243e-01]],\n",
      "\n",
      "           [[ 2.3340e-01, -6.6623e-01,  7.0928e-01,  ...,  5.7340e-01,\n",
      "             -3.4302e-01,  5.1717e-01],\n",
      "            [-9.1995e-02,  5.3384e-01, -9.6278e-01,  ...,  2.5272e-01,\n",
      "             -2.2079e+00,  1.4422e-01],\n",
      "            [ 3.9809e-01, -3.1638e-02, -1.5493e+00,  ..., -6.7171e-01,\n",
      "             -1.2464e+00,  5.0384e-01],\n",
      "            ...,\n",
      "            [-2.1438e+00,  3.6685e-01,  2.2019e-01,  ..., -2.6380e-01,\n",
      "             -5.9139e-01,  1.5964e+00],\n",
      "            [ 3.1837e-01, -4.4028e-01,  9.5373e-02,  ..., -1.7385e+00,\n",
      "             -5.5111e-01, -2.5217e-01],\n",
      "            [-6.9273e-01, -1.2980e+00, -9.0371e-01,  ...,  2.7742e-01,\n",
      "             -1.8561e+00,  7.7067e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 2.2621e+00,  2.9715e-01, -1.8835e-01,  ..., -1.5499e+00,\n",
      "             -2.1790e-01, -1.2308e+00],\n",
      "            [-1.7604e-01,  9.9610e-01,  1.8423e+00,  ...,  2.6618e-01,\n",
      "             -2.7802e-01, -2.0214e+00],\n",
      "            [ 2.3643e-01, -1.8501e+00, -3.7632e-01,  ...,  8.6165e-01,\n",
      "              4.0843e-01, -9.4709e-02],\n",
      "            ...,\n",
      "            [-1.9080e-01,  2.9708e-01,  2.7598e-01,  ..., -5.3136e-01,\n",
      "             -3.1430e-01,  6.3484e-01],\n",
      "            [ 9.8665e-02, -3.4184e-01,  3.2971e-01,  ..., -9.5574e-01,\n",
      "             -1.2200e+00, -7.2834e-01],\n",
      "            [-1.9605e+00, -9.9087e-01,  1.0794e-01,  ..., -6.9226e-01,\n",
      "             -3.2869e-01,  1.0837e+00]],\n",
      "\n",
      "           [[-6.4215e-01, -9.8790e-01, -3.3463e-01,  ..., -9.0262e-01,\n",
      "             -3.5761e-01,  9.8701e-01],\n",
      "            [ 2.7168e-01,  2.5790e-01,  7.3234e-01,  ...,  4.6540e-01,\n",
      "              4.3723e-01,  7.2762e-01],\n",
      "            [-1.5413e+00,  8.8795e-01,  4.7454e-01,  ...,  1.5376e+00,\n",
      "              9.1917e-01, -1.2907e+00],\n",
      "            ...,\n",
      "            [-4.6905e-02,  1.5448e+00, -7.8321e-01,  ...,  6.9309e-01,\n",
      "              9.8099e-01, -6.5441e-01],\n",
      "            [-1.4639e+00, -1.3131e+00, -9.3895e-01,  ...,  6.8951e-01,\n",
      "             -6.8285e-01, -1.3319e+00],\n",
      "            [-5.4145e-01,  7.8977e-01,  2.2813e+00,  ...,  1.2794e+00,\n",
      "             -1.1581e+00,  4.5630e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[-9.6324e-01,  1.7313e+00, -2.4709e-01,  ..., -1.5729e+00,\n",
      "             -1.2171e+00, -1.0450e-01],\n",
      "            [-2.5145e-01,  1.9697e+00, -6.4044e-01,  ...,  1.7907e+00,\n",
      "             -7.7928e-01,  8.1318e-01],\n",
      "            [-1.2356e+00,  1.7073e+00,  3.9869e-01,  ..., -1.1299e+00,\n",
      "             -1.7932e+00, -1.1246e+00],\n",
      "            ...,\n",
      "            [ 1.2481e+00,  3.8671e-02, -1.7387e+00,  ...,  2.1234e+00,\n",
      "              6.7691e-01,  4.8473e-01],\n",
      "            [-9.0467e-01, -9.9546e-01,  7.5467e-01,  ...,  3.6104e-01,\n",
      "             -6.7521e-01,  1.6077e+00],\n",
      "            [-6.6550e-01, -8.2050e-01,  5.6213e-01,  ...,  1.5999e+00,\n",
      "             -3.3942e-03, -1.5341e-01]],\n",
      "\n",
      "           [[-4.0918e-01,  8.8909e-01,  7.6902e-01,  ...,  5.4519e-01,\n",
      "             -4.9179e-01, -6.6126e-01],\n",
      "            [ 2.4204e-01,  4.4693e-01, -7.2437e-01,  ..., -3.8357e-02,\n",
      "             -1.9290e+00, -1.9735e+00],\n",
      "            [-1.7713e+00,  1.1403e+00, -7.7057e-01,  ..., -4.4093e-01,\n",
      "             -1.4668e+00, -1.7402e-01],\n",
      "            ...,\n",
      "            [ 1.8400e+00, -5.0607e-01,  1.1049e+00,  ..., -2.1386e-02,\n",
      "             -9.9082e-03,  6.9186e-02],\n",
      "            [-4.2810e-01,  1.8972e-01,  1.5825e-01,  ...,  1.1122e+00,\n",
      "             -1.9157e-01, -1.1284e+00],\n",
      "            [ 1.3040e+00,  6.8241e-01,  4.2165e-01,  ...,  1.0651e+00,\n",
      "              1.6098e-01, -5.0152e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 6.7596e-02, -1.9791e-02,  2.3921e-01,  ..., -2.2253e-03,\n",
      "              2.3355e+00, -3.2800e-01],\n",
      "            [ 8.1515e-02,  1.4610e+00,  1.9985e-01,  ...,  3.7570e-01,\n",
      "             -9.3357e-01, -9.6369e-02],\n",
      "            [ 1.3340e+00, -4.9983e-02,  2.5250e+00,  ..., -1.2470e+00,\n",
      "             -4.0869e-01, -2.4909e+00],\n",
      "            ...,\n",
      "            [ 2.0623e+00, -6.4191e-01,  8.9615e-01,  ...,  6.1945e-01,\n",
      "              6.5718e-02, -1.3650e+00],\n",
      "            [ 4.0777e-01, -9.4476e-01,  3.6204e-01,  ..., -5.7622e-01,\n",
      "             -5.7128e-01,  1.3526e-01],\n",
      "            [ 1.2742e+00,  1.3715e+00,  6.4897e-01,  ..., -6.5424e-01,\n",
      "             -1.1642e-02,  1.0656e-01]],\n",
      "\n",
      "           [[-1.2685e+00,  8.2768e-01,  1.8201e+00,  ..., -1.6976e-01,\n",
      "              1.6610e+00,  3.5477e-01],\n",
      "            [-2.2989e+00, -7.1995e-02,  9.7946e-01,  ...,  2.0062e-01,\n",
      "             -7.9667e-01,  6.2141e-01],\n",
      "            [-1.9809e-02,  4.8510e-01, -1.3676e+00,  ..., -2.3408e+00,\n",
      "             -1.0861e+00, -2.6063e-01],\n",
      "            ...,\n",
      "            [-4.3223e-02, -4.2233e-01,  3.7664e-01,  ...,  1.0594e+00,\n",
      "              1.4987e+00, -2.7041e+00],\n",
      "            [-1.0106e+00, -1.4050e+00, -1.6568e+00,  ...,  1.0448e+00,\n",
      "             -9.6771e-01,  1.3650e+00],\n",
      "            [-4.9470e-01,  3.3569e-02,  2.4018e+00,  ...,  2.7607e-01,\n",
      "             -1.1638e+00,  5.1441e-01]]]]]])\n",
      "tensor([[[[[[-0.0418,  0.1044,  0.0854,  ..., -0.0147,  0.1336,  0.2245],\n",
      "            [-0.0115, -0.0012,  0.0542,  ...,  0.2244, -0.0934, -0.1388],\n",
      "            [ 0.1376,  0.6128,  0.0069,  ...,  0.0477,  0.2013,  0.0967],\n",
      "            ...,\n",
      "            [-0.3711, -0.2252,  0.2845,  ...,  0.1030,  0.2091,  0.1220],\n",
      "            [-0.1743, -0.6126,  0.2119,  ...,  0.1943,  0.2056, -0.0049],\n",
      "            [-0.0149,  0.1988, -0.1012,  ...,  0.2168, -0.0640,  0.1913]],\n",
      "\n",
      "           [[-0.0568, -0.1493, -0.1161,  ...,  0.0811, -0.0850,  0.0261],\n",
      "            [ 0.1277,  0.1921,  0.0944,  ...,  0.3307,  0.4866,  0.2204],\n",
      "            [-0.1642,  0.1683,  0.0033,  ..., -0.0553, -0.5604, -0.2296],\n",
      "            ...,\n",
      "            [-0.1536, -0.0767,  0.4317,  ...,  0.1455,  0.3144,  0.3992],\n",
      "            [ 0.0241, -0.2194, -0.5031,  ...,  0.1165,  0.6185,  0.2478],\n",
      "            [ 0.1506,  0.0612, -0.1067,  ..., -0.2645, -0.2490,  0.0914]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[-0.0517,  0.1410, -0.1044,  ...,  0.0130, -0.0813, -0.0101],\n",
      "            [-0.0492, -0.0239, -0.2481,  ..., -0.2845, -0.4066,  0.5980],\n",
      "            [-0.0513, -0.5648, -0.4745,  ..., -0.0682, -0.0202,  0.3155],\n",
      "            ...,\n",
      "            [ 0.0687,  0.2675,  0.2543,  ..., -0.1286, -0.2384,  0.3604],\n",
      "            [ 0.1576, -0.0773, -0.2291,  ..., -0.5501,  0.2691, -0.0625],\n",
      "            [-0.3338,  0.0362,  0.2445,  ...,  0.1182, -0.0639,  0.2072]],\n",
      "\n",
      "           [[-0.1515, -0.1273,  0.1884,  ..., -0.1562,  0.2159, -0.0250],\n",
      "            [-0.1301, -0.3555, -0.5323,  ...,  0.0745,  0.1133,  0.2702],\n",
      "            [-0.1004, -0.0542, -0.5130,  ...,  0.0394, -0.0221, -0.0586],\n",
      "            ...,\n",
      "            [-0.1530,  0.1551, -0.0921,  ...,  0.3056, -0.0627, -0.2352],\n",
      "            [-0.4225,  0.0946,  0.1568,  ...,  0.0181,  0.2625,  0.1524],\n",
      "            [ 0.0900, -0.2427,  0.1219,  ..., -0.1476, -0.2683,  0.0027]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[-0.3964,  0.1728, -0.3515,  ...,  0.2178,  0.1217,  0.3506],\n",
      "            [-0.0681, -0.2484,  0.3647,  ..., -0.1572,  0.1928,  0.1468],\n",
      "            [ 0.2131,  0.6077, -0.4520,  ...,  0.0960, -0.6480, -0.3895],\n",
      "            ...,\n",
      "            [ 0.2860, -0.1100, -0.1039,  ...,  0.5079,  0.0765, -0.1737],\n",
      "            [-0.1336,  0.1579, -0.1609,  ...,  0.1351, -0.0668, -0.1705],\n",
      "            [ 0.0471,  0.1367,  0.0284,  ...,  0.0997, -0.1440,  0.1717]],\n",
      "\n",
      "           [[ 0.0398,  0.0109,  0.2824,  ...,  0.2757,  0.2776, -0.1775],\n",
      "            [ 0.0768, -0.0231, -0.3745,  ..., -0.4415, -0.3578, -0.1714],\n",
      "            [ 0.0207,  0.4031,  0.3937,  ...,  0.0135, -0.3886, -0.4347],\n",
      "            ...,\n",
      "            [ 0.1784,  0.2710,  0.1697,  ..., -0.2395,  0.2954, -0.2004],\n",
      "            [ 0.3161,  0.7365,  0.1424,  ...,  0.2243,  0.4615,  0.4546],\n",
      "            [-0.1839, -0.1426, -0.3033,  ..., -0.2830, -0.1893, -0.1449]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.0858, -0.2396, -0.2825,  ...,  0.2301, -0.2176, -0.0946],\n",
      "            [ 0.1886,  0.1012,  0.0074,  ..., -0.3442, -0.0470,  0.4937],\n",
      "            [ 0.0898, -0.1157,  0.6656,  ...,  0.1214, -0.0398,  0.2496],\n",
      "            ...,\n",
      "            [-0.2238,  0.2251,  0.2244,  ..., -0.2147,  0.2666, -0.1031],\n",
      "            [ 0.0664,  0.2373,  0.1116,  ...,  0.2579, -0.5158, -0.2642],\n",
      "            [ 0.1433,  0.1013, -0.1033,  ..., -0.0082, -0.1476, -0.0403]],\n",
      "\n",
      "           [[-0.1636, -0.0736, -0.0705,  ..., -0.1496, -0.0334,  0.2118],\n",
      "            [ 0.1898, -0.0580, -0.0617,  ..., -0.3111,  0.1729,  0.6572],\n",
      "            [-0.3144,  0.4291, -0.0191,  ...,  0.6902,  0.1997, -0.1516],\n",
      "            ...,\n",
      "            [ 0.3970,  0.1616,  0.8291,  ...,  0.0889, -0.4306, -0.1378],\n",
      "            [ 0.1155,  0.1574, -0.3695,  ..., -0.0897, -0.2043, -0.0575],\n",
      "            [-0.1653,  0.0955,  0.0890,  ..., -0.1129, -0.2259,  0.1575]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.2367,  0.2885,  0.1431,  ..., -0.1955, -0.1972,  0.0118],\n",
      "            [-0.1431,  0.4493, -0.1615,  ...,  0.5461,  0.0723,  0.1430],\n",
      "            [ 0.1966, -0.0989, -0.4373,  ..., -0.5726,  0.4366,  0.1240],\n",
      "            ...,\n",
      "            [-0.2851,  0.4988,  0.0715,  ..., -0.0117, -0.4853, -0.5395],\n",
      "            [-0.3159, -0.4902, -0.1430,  ...,  0.2961, -0.2219,  0.1792],\n",
      "            [-0.0535,  0.1680,  0.1082,  ...,  0.0597, -0.0022,  0.1140]],\n",
      "\n",
      "           [[-0.0113,  0.1908, -0.2773,  ..., -0.0385, -0.1479, -0.0484],\n",
      "            [ 0.0486, -0.0783,  0.3199,  ...,  0.0407,  0.8876,  0.4594],\n",
      "            [-0.4734, -0.4023,  0.0854,  ...,  0.0511, -0.0438,  0.3596],\n",
      "            ...,\n",
      "            [-0.1197, -0.1639,  0.4563,  ..., -0.4347,  0.2947,  0.1558],\n",
      "            [ 0.2015,  0.1956, -0.1748,  ...,  0.1442,  0.2185, -0.1042],\n",
      "            [-0.1013, -0.6203, -0.3548,  ...,  0.2533,  0.0931,  0.1838]]]]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from models.modules.unet import Unet\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "net = Unet(\n",
    "    in_channels=2,\n",
    "    out_channels=2,\n",
    "    hidden_channels=[8,10],\n",
    "    n_enc_cab=[2,2,2],\n",
    "    n_dec_cab=[2,2,2],\n",
    "    n_skip_cab=[1,1,1],\n",
    "    n_cab_bottle=3\n",
    ")\n",
    "\n",
    "x = torch.randn(1, 5,1,2,100,100)\n",
    "\n",
    "print(x)\n",
    "\n",
    "x = net(x)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss localloss: -0.001828571199439466\n"
     ]
    }
   ],
   "source": [
    "from models.modules.context import ExtraContext, register_extra_loss, register_extra_hook, get_extra_context\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# In sub module:\n",
    "class SubModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        register_extra_loss(self, x.mean(), \"localloss\")\n",
    "\n",
    "        def dosomething_hook():\n",
    "            return x.mean()\n",
    "        register_extra_hook(self, dosomething_hook, \"This is a submodel hook\")\n",
    "        if ctx := get_extra_context(self):\n",
    "            ctx['local_var'] = 'This is a local variable'\n",
    "        return x\n",
    "\n",
    "# In top module:\n",
    "class TopModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.subm = SubModel()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.subm(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# In training step:\n",
    "batch = torch.randn(10, 3, 32, 32, requires_grad=True)  # Example input batch\n",
    "target = batch\n",
    "\n",
    "lossfn = lambda x, y: x.mean()\n",
    "\n",
    "model = TopModel()\n",
    "with ExtraContext(model) as ctx:\n",
    "    pred = model(batch)\n",
    "\n",
    "    # ... training step\n",
    "\n",
    "    losses = ctx.losses\n",
    "    hooks = ctx.hooks\n",
    "    # losses, hooks, objects are lists of tuples:\n",
    "    # (prefix, loss) for every loss\n",
    "    # (prefix, hook) for every hook\n",
    "\n",
    "    loss = lossfn(pred, target)\n",
    "    for prefix, localoss in losses:\n",
    "        print(f\"Loss {prefix}: {loss.item()}\")\n",
    "        loss += localoss\n",
    "    loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Linear(16, 10)\n",
    "\n",
    "class TopModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.submodel = MyModel()\n",
    "        self.submodel2 = self.submodel\n",
    "        self.submodel3 = self.submodel\n",
    "\n",
    "model = TopModel()\n",
    "\n",
    "# 遍历模型的模块及其前缀\n",
    "for prefix, module in model.named_modules():\n",
    "    print(f\"Prefix: {prefix}, Module: {module}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn([1231])\n",
    "\n",
    "x.extraloss = torch.randn([1231, 2])\n",
    "\n",
    "print(x.extraloss)\n",
    "\n",
    "y = x + 1\n",
    "\n",
    "print(y.extraloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.param = nn.Parameter(torch.tensor(1.0))\n",
    "        self.extra_data = {\"custom_key\": 123}  # 自定义状态\n",
    "\n",
    "    def get_extra_state(self):\n",
    "        # 返回额外状态\n",
    "        return self.extra_data\n",
    "\n",
    "    def set_extra_state(self, state):\n",
    "        # 恢复额外状态\n",
    "        self.extra_data = state\n",
    "\n",
    "model = CustomModule()\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# 保存额外状态\n",
    "torch.save(model.get_extra_state(), \"extra_state.pth\")\n",
    "\n",
    "# 加载模型\n",
    "extra_state = torch.load(\"extra_state.pth\")\n",
    "model.set_extra_state(extra_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class SubModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = torch.tensor(0.0)\n",
    "\n",
    "    def state_dict(self, destination=None, prefix='', keep_vars=False):\n",
    "        state = super().state_dict(destination = destination, prefix = prefix, keep_vars = keep_vars)\n",
    "        state[prefix + 'loss'] = self.loss\n",
    "        return state\n",
    "\n",
    "    def forward(self, x):\n",
    "        loss = x.mean()\n",
    "\n",
    "        def get_loss():\n",
    "            return loss\n",
    "        \n",
    "        self.get_loss = get_loss\n",
    "\n",
    "        return x\n",
    "\n",
    "class TopModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.subModule = SubModule()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.subModule(x)\n",
    "        return x\n",
    "\n",
    "tb = TopModule()\n",
    "\n",
    "x = torch.randn(2,2, requires_grad=True)\n",
    "x = tb(x)\n",
    "\n",
    "for m in tb.modules():\n",
    "    if hasattr(m, \"get_loss\"):\n",
    "        print(m.get_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SubModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubModule, self).__init__()\n",
    "        self.sub_param = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
    "        \n",
    "class ParentModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParentModule, self).__init__()\n",
    "        self.parent_param = nn.Parameter(torch.tensor([4.0, 5.0, 6.0]))\n",
    "        self.sub_module = SubModule()  # 子模块\n",
    "        \n",
    "parent_model = ParentModule()\n",
    "\n",
    "# 访问父模块的 state_dict\n",
    "state_dict = parent_model.state_dict()\n",
    "print(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vqpromptunet import VQPromptUnet\n",
    "\n",
    "m = VQPromptUnet(2,2,4,[2,4,6],[2,2,2],[2,2,2],[2,2,2],[2,2,2],[2,2,2],[2,2,2],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "path = \"/home/hulabdl/CMRxRecon2025/R1_mat_folder/\"\n",
    "\n",
    "filelist = glob(os.path.join(path, \"*.mat\"))\n",
    "filelist = [file for file in filelist if 'mask' not in file.lower()]\n",
    "\n",
    "scorepath = \"/home/hulabdl/PromptMR-plus/scorelist.txt\"\n",
    "\n",
    "scores = []\n",
    "\n",
    "with open(scorepath, 'r') as f:\n",
    "    for line in f:\n",
    "        scores.append(line.strip().split())\n",
    "\n",
    "res = []\n",
    "\n",
    "for cond in scores:\n",
    "    for file in filelist:\n",
    "        flag = True\n",
    "        for keyword in cond:\n",
    "            if keyword.lower() not in file.lower():\n",
    "                flag = False\n",
    "\n",
    "        if flag:\n",
    "            res.append((cond, file))\n",
    "\n",
    "\n",
    "for line in res:\n",
    "    print(line)\n",
    "\n",
    "print(len(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "for cond, file in res:\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        data = f['kus']\n",
    "        shape = data.shape\n",
    "        if len(shape) == 4:\n",
    "            shape = [1] + list(shape)\n",
    "        print(file, \"\\t\".join(map(str, shape)), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_mat_files(directory):\n",
    "    mat_files = []\n",
    "    # 遍历目录及其子目录\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mat\") and \"kus\" in file:  # 检查文件扩展名\n",
    "                mat_files.append(os.path.join(root, file))  # 获取完整路径\n",
    "    return mat_files\n",
    "\n",
    "# 示例用法\n",
    "directory = \"/home/hulabdl/PromptMR-plus/valres1\"\n",
    "mat_files = get_mat_files(directory)\n",
    "print(f\"Found .mat files:{len(mat_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/hulabdl/CMRxRecon2025/ChallengeData/T1rho/TrainingSet/FullSample/Center001/UIH_30T_umr780/P002/T1rho.mat'\n",
    "\n",
    "import h5py\n",
    "from scipy.io import loadmat as loadmat_scipy\n",
    "\n",
    "def loadmat_group(group):\n",
    "    \"\"\"\n",
    "    Load a group in Matlab v7.3 format .mat file using h5py.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for k, v in group.items():\n",
    "        if isinstance(v, h5py.Dataset):\n",
    "            data[k] = v[()]\n",
    "        elif isinstance(v, h5py.Group):\n",
    "            data[k] = loadmat_group(v)\n",
    "    return data\n",
    "\n",
    "def loadmat(filename):\n",
    "    \"\"\"\n",
    "    Load Matlab v7.3 format .mat file using h5py.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            data = {}\n",
    "            for k, v in f.items():\n",
    "                if isinstance(v, h5py.Dataset):\n",
    "                    data[k] = v[()]\n",
    "                elif isinstance(v, h5py.Group):\n",
    "                    data[k] = loadmat_group(v)\n",
    "    except OSError as e:\n",
    "        f = loadmat_scipy(filename)\n",
    "        data = {key: value for key, value in f.items() if not key.startswith('__')}\n",
    "    return data\n",
    "\n",
    "data = loadmat(path)\n",
    "print(data.keys())\n",
    "print(data['kspace'].shape)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# print(np.sum(data['mask'][0], axis=0)[0]-21) \n",
    "# plt.imshow(data['mask'][0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def loadmat_group(group):\n",
    "    \"\"\"\n",
    "    Load a group in Matlab v7.3 format .mat file using h5py.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for k, v in group.items():\n",
    "        if isinstance(v, h5py.Dataset):\n",
    "            data[k] = v[()]\n",
    "        elif isinstance(v, h5py.Group):\n",
    "            data[k] = loadmat_group(v)\n",
    "    return data\n",
    "\n",
    "def loadmat(filename):\n",
    "    \"\"\"\n",
    "    Load Matlab v7.3 format .mat file using h5py.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            data = {}\n",
    "            for k, v in f.items():\n",
    "                if isinstance(v, h5py.Dataset):\n",
    "                    data[k] = v[()]\n",
    "                elif isinstance(v, h5py.Group):\n",
    "                    data[k] = loadmat_group(v)\n",
    "    except OSError as e:\n",
    "        f = loadmat_scipy(filename)\n",
    "        data = {key: value for key, value in f.items() if not key.startswith('__')}\n",
    "    return data\n",
    "\n",
    "for mat in mat_files:\n",
    "    data = loadmat(mat)\n",
    "    recon = torch.as_tensor(data['img4ranking'])\n",
    "    is_nan = not torch.isfinite(recon).any()\n",
    "    if is_nan:\n",
    "        print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='/home/hulabdl/PromptMR-plus/blackblood_kus_ktRadial16.mat'\n",
    "path = \"/home/hulabdl/PromptMR-plus/blackblood_kus_ktRadial8.mat\"\n",
    "# path = \"/nas-data/datasets/CMRxRecon2025/TaskR1/MultiCoil/BlackBlood/ValidationSet/UnderSample_TaskR1/Center006/Siemens_30T_Prisma/P018/blackblood_kus_ktRadial16.mat\"\n",
    "\n",
    "import h5py\n",
    "from scipy.io import loadmat as loadmat_scipy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = loadmat(path)\n",
    "print(data.keys())\n",
    "print(data['img4ranking'].shape)\n",
    "\n",
    "import torch\n",
    "\n",
    "tensor = torch.as_tensor(data['img4ranking'])\n",
    "\n",
    "print(tensor)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(data['img4ranking'][1], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/hulabdl/CMRxRecon2025/ChallengeData/MultiCoil/T1w/TrainingSet/Mask_TaskAll/Center003/UIH_30T_umr880/P004/T1w_mask_ktRadial16.mat'\n",
    "\n",
    "import h5py\n",
    "from scipy.io import loadmat as loadmat_scipy\n",
    "\n",
    "def loadmat_group(group):\n",
    "    \"\"\"\n",
    "    Load a group in Matlab v7.3 format .mat file using h5py.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for k, v in group.items():\n",
    "        if isinstance(v, h5py.Dataset):\n",
    "            data[k] = v[()]\n",
    "        elif isinstance(v, h5py.Group):\n",
    "            data[k] = loadmat_group(v)\n",
    "    return data\n",
    "\n",
    "def loadmat(filename):\n",
    "    \"\"\"\n",
    "    Load Matlab v7.3 format .mat file using h5py.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            data = {}\n",
    "            for k, v in f.items():\n",
    "                if isinstance(v, h5py.Dataset):\n",
    "                    data[k] = v[()]\n",
    "                elif isinstance(v, h5py.Group):\n",
    "                    data[k] = loadmat_group(v)\n",
    "    except OSError as e:\n",
    "        f = loadmat_scipy(filename)\n",
    "        data = {key: value for key, value in f.items() if not key.startswith('__')}\n",
    "    return data\n",
    "\n",
    "data = loadmat(path)\n",
    "print(data['mask'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
